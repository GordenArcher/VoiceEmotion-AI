# Voice Emotion AI

A **Speech Emotion Recognition (SER)** system built with **React Native (frontend)** and **Django REST Framework (backend)**, with a machine-learning model trained in **Google Colab**. The application records audio on mobile, sends it to a Django API, and receives predicted emotions such as *happy, sad, angry, calm,* etc.

This README provides:

* Full project overview
* Architecture
* Folder structure
* Backend (Django) setup
* Frontend (React Native) setup
* Authentication workflow
* Upload flow
* Model training (placeholder, to be added)
* Common errors & debugging

---

## Project Overview

Voice Emotion AI enables users to record their voice on mobile and get an emotion classification. It integrates:

### **Frontend (React Native)**

* Records audio
* Uses Expo or bare RN (depending on your environment)
* Sends audio to Django using authenticated requests (access + refresh token)
* Handles token refresh for long-running sessions

### **Backend (Django + DRF)**

* Provides JWT authentication
* Accepts audio uploads securely
* Runs inference using a trained SER ML model
* Returns predicted emotion + confidence score

### **Machine Learning Model (Google Colab)**

* Reads dataset (RAVDESS)
* Extracts MFCC features
* Trains CNN or LSTM model
* Exports model as `.h5` or `.pt`
* Loaded by Django at runtime

---

## Folder Structure

```
voice-emotion-ai/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â”œâ”€â”€ emoapp/
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ utils.py   # ML model loading + inference
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ ml_models/
â”‚   â”‚       â”œâ”€â”€ emotional_recognition_model.h5 or model.pt
â”‚   â”‚       â””â”€â”€ label_encoder.pkl
â”‚   â”‚       â””â”€â”€ scaler.pkl
â”‚   â””â”€â”€ media/
â”‚       â””â”€â”€ audio_uploads/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ axiosConfig.js
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useAuthRefresh.js
â”‚   â”‚   â”œâ”€â”€ tabs/
â”‚   â””â”€â”€ assets/
â”‚
â””â”€â”€ model-training/   # to be added
    â””â”€â”€ colab_notebook.ipynb
```

---

## Backend Setup (Django)

### **Install dependencies**

```
pip install -r requirements.txt
```

### **Run migrations**

```
python manage.py migrate
```

### **Start backend**

```
python manage.py runserver
```

---

## Authentication Workflow (Very Important)

The system uses **JWT** with:

* Access Token (short-lived)
* Refresh Token (long-lived)

### How your app works now:

1. User logs in â†’ receives access + refresh
2. Access token expires â†’ upload requests start failing (`401 Unauthorized`)
3. React Native should automatically call refresh endpoint
4. Backend issues a new access token
5. Upload retry succeeds

If refresh is not called â†’ audio upload fails.

---

## Audio Upload Flow

### **Frontend**

1. Record audio using `expo-av` or `react-native-audio-recorder-player`
2. Convert audio â†’ `FormData`
3. Send `POST /recordings/upload/` with header:

```
Authorization: Bearer <access_token>
```

4. If `401` â†’ call refresh token

### **Backend**

1. Receives audio
2. Saves to `media/voice_recordings/`
3. Loads ML model
4. Extracts MFCC features
5. Runs prediction
6. Returns:

```json
{
  "emotion": "happy",
  "confidence": 0.92
}
```

---

## Model Training (to add later)

Include:

* Dataset download steps
* Preprocessing (MFCC extraction)
* Model architecture
* Training logs
* Export steps

---

## Common Issues & Fixes

### **1. Mobile doesnâ€™t need CORS**

Correct â†’ CORS does **not** apply to React Native mobile apps.
Only browsers.

### **2. Unauthorized on upload**

Caused by **expired access token**.
Fix: implement refresh.

### **3. Django logs not showing**

Add this to `settings.py`:

```
LOGGING = {
    "version": 1,
    "handlers": {"console": {"class": "logging.StreamHandler"}},
    "loggers": {
        "django": {"handlers": ["console"], "level": "DEBUG"},
        "emotion_app": {"handlers": ["console"], "level": "DEBUG"},
    },
}
```

### **4. Cannot find name 'colorScheme'**

Use:

```
import { useColorScheme } from 'react-native';
const colorScheme = useColorScheme();
```

---

## ðŸ“± Frontend Setup (React Native)

Install dependencies:

```
npm install
npx expo install expo-av
npm install axios
```

Run app:

```
npx expo start
```

---

## API Endpoints

### **Auth**

* `POST /auth/login/`
* `POST /auth/register/`

### **Emotion Prediction**

* `POST /recordings/upload/`

---

## Testing

Use Postman / Thunder Client to verify:

1. Login
2. Upload audio
3. Verify response

---

## License

MIT

---

## Contributing

Pull requests welcome. Open issues before major changes to discuss direction.
